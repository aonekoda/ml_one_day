{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aonekoda/ml_one_day/blob/main/Model_Selecion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5teXwHrHWL1"
      },
      "source": [
        "# 모형의 선택\n",
        "* 최적의 모형을 선택하기 위해 적당한 하이퍼파라미터의 설정이 중요하다.\n",
        "* 여러가지의 후보 모형에서 효율적으로 최선의 모형을 선택하는 기법을 다룬다.\n",
        "    * 완전탐색 기법 \n",
        "    * 랜덤탐색 기법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0O17oq2HWL7"
      },
      "source": [
        "### 완전탐색 기법\n",
        "사이킷런의 GridSearchCV를 사용한다. 하이퍼파라미터의 **모든 조합**으로 모형을 훈련하여 최적의 하이퍼파라미터를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSf_tDlUHWL8"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "import numpy as np\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WNUl4ZHWL9"
      },
      "source": [
        "하이퍼파라미터의 후보값을 설정한다.   \n",
        "penalty 방법과 규제 변수인 C에 적당한 후보값을 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E2qOq65HWL-"
      },
      "outputs": [],
      "source": [
        "# 페널티(penalty) 하이퍼파라미터 값의 후보를 만듭니다.\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# 규제 하이퍼파라미터 값의 후보 범위를 만듭니다.\n",
        "C = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# 하이퍼파라미터 후보 딕셔너리를 만듭니다.\n",
        "hyperparameters = dict(C=C, penalty=penalty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9AnXxrXHWL-"
      },
      "source": [
        "* 사이킷런의 그리드 서치 기능은 모든 조합에 대해 모형을 훈련한다.  \n",
        "* 최고의 성능을 내는 모형을 최종 모형으로 선택한다.  \n",
        "* K-fold cross validation기법을 사용한다.\n",
        "### GridSearchCV\n",
        "* verbose =0 이면 아무것도 출력하지 않고 1~3 값을 주면 자세한 내용이 출력된다.\n",
        "* n_jobs = -1 로 설정하면 모든 CPU 코어를 사용하여 병렬로 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxciCps5HWL_"
      },
      "outputs": [],
      "source": [
        "# 그리드 서치 객체를 만듭니다.\n",
        "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
        "\n",
        "# 그리드 서치를 수행합니다.\n",
        "best_model = gridsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGv1A1kTHWMA"
      },
      "source": [
        "* 모든 조합에 대해 모형을 훈련하므로 시간이 많이 소요될 수 있다.\n",
        "* 위 설정에서 패널티는 2개, C 규제변수의 값은 5개, fold 수는 5개  \n",
        "* 총 2x5x5 = 50개의 모형중 최선의 모형을 선택한다.\n",
        "* GridSearchCV가 완료되면 최선의 모형을 만드는 하이퍼파라미터를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ZukgSVHWMB",
        "outputId": "69295ec0-af47-4e44-8a77-d44c43456efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "가장 좋은 페널티: l1\n",
            "가장 좋은 C 값: 10\n"
          ]
        }
      ],
      "source": [
        "# 최선의 하이퍼파라미터를 확인합니다.\n",
        "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoiPFhrVHWMC",
        "outputId": "24e2d696-9683-4d06-a174-67d1f2e5f1f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 최적의 하이퍼파라미터를 적용한 모형의 성능을 확인한다.\n",
        "best_model.score(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFJTnRUvHWMD"
      },
      "source": [
        "### 랜덤탐색 기법\n",
        "사이킷런의 RandomizedSearchCV을 사용한다. 완전탐색 기법보다는 최적 모형을 선택하는데 드는 계산 비용을 줄인다. 랜덤한 하이퍼파라미터의 조합으로 조사한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAD6eLbQHWMD"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "from scipy.stats import uniform\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic = linear_model.LogisticRegression(solver='liblinear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmxGm2GmHWME"
      },
      "source": [
        "하이퍼파라미터의 후보값을 설정한다.  \n",
        "penalty 방법과 규제 변수인 C에 적당한 후보값을 설정한다.\n",
        "\n",
        "### RandomizedSearchCV\n",
        "RandomizedSearchCV에서 분포를 지정하면 이 분포에서 중복을 허용하지 않도록 하이퍼파라미터의 값을 랜덤하게 샘플링한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is2lndtxHWME"
      },
      "outputs": [],
      "source": [
        "# 페널티 하이퍼파라미터 후보를 만듭니다. penalty hyperparameter values\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# 규제 하이퍼파라미터 값의 후보를 위한 분포를 만듭니다.\n",
        "C = uniform(loc=0, scale=100) # 0~100 사이의 균등분포에서 랜덤하게 샘플링한다.\n",
        "\n",
        "# 하이퍼파라미터 옵션을 만듭니다.\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "# 랜덤 서치 객체를 만듭니다.\n",
        "randomizedsearch = RandomizedSearchCV(\n",
        "    logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0,\n",
        "    n_jobs=-1)\n",
        "\n",
        "# 랜덤 서치를 수행합니다.\n",
        "best_model = randomizedsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FC8ohEeHWMF"
      },
      "source": [
        "GridSearchCV에서와 마찬가지로 최적 모형의 하이퍼파라미터를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INwrz-LCHWMF",
        "outputId": "ce77cff5-c944-4ba6-f756-7826993a490d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "가장 좋은 페널티: l2\n",
            "가장 좋은 C 값: 93.25573593386588\n"
          ]
        }
      ],
      "source": [
        "# 최선의 하이퍼파라미터를 확인합니다.\n",
        "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGsysh0ZHWMF",
        "outputId": "5f248b9a-f39b-4b13-9893-ca26defbd748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 최적의 하이퍼파라미터를 적용한 모형의 성능을 확인한다.\n",
        "best_model.score(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLUFtWthHWMG"
      },
      "source": [
        "### 여러 학습 알고리즘에서 최선의 모델 선택하기\n",
        "\n",
        "다양한 학습 알고리즘과 각각의 하이퍼파라미터를 탐색하여 최선의 모형을 선택한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEdwpbwxHWMG"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 랜덤 시드를 설정합니다.\n",
        "np.random.seed(0)\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 파이프라인을 만듭니다.\n",
        "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6kQHBrrHWMG"
      },
      "source": [
        "로지스틱 회귀 모형과 랜덤포레스트 두 개의 학습 알고리즘을 학습 탐색에 포함 시킨다. \n",
        "딕셔너리를 사용하여 학습 알고리즘과 탐색하고자하는 하이퍼파라미터를 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnn5czpHWMH"
      },
      "outputs": [],
      "source": [
        "# 후보 학습 알고리즘과 하이퍼파라미터로 딕셔너리를 만듭니다.\n",
        "search_space = [{\"classifier\": [LogisticRegression(solver='liblinear', max_iter=500)],\n",
        "                 \"classifier__penalty\": ['l1', 'l2'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10)},\n",
        "                {\"classifier\": [RandomForestClassifier()],\n",
        "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
        "                 \"classifier__max_features\": [1, 2, 3]}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_sP_0JHWMH"
      },
      "outputs": [],
      "source": [
        "# 그리드 서치 객체를 만듭니다.\n",
        "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
        "\n",
        "# 그리드 서치를 수행합니다.\n",
        "best_model = gridsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JntCuG9fHWMH",
        "outputId": "9df5fa8b-2d7a-4ab8-bf07-1ae0d0e555e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=7.742636826811269, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=500, multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 최선의 모델을 확인합니다.\n",
        "best_model.best_estimator_.get_params()[\"classifier\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nayf2fMIHWMI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Model_Selecion.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
